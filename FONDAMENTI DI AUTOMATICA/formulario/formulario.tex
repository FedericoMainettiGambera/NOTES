\fontsize{6pt}{8pt}\selectfont
\newgeometry{
    lmargin=0.2cm,
    rmargin=0.2cm,
    tmargin=0.2cm,
    bmargin=0.2cm,
}
\begin{landscape}
\begin{multicols*}{3}
    \subsection*{Terminologia}
    \[
        \begin{cases}
            \dot{x}(t) = f(x(t),u(t),t) = Ax + bu\\
            y(t) = g(x(t),u(t),t) = cx +du
        \end{cases}
    \]
    \textbf{Stato}: le varie $x$;\newline
    \textbf{Uscita}: $y$;\newline
    \textbf{Sistema dinamico}: se la conoscenza degli ingressi su un intervallo di tempo
    non è sufficiente per determinare l’andamento delle uscite sullo stesso intervallo di tempo.\newline
    \textbf{Ordine del sistema}: numero di variabili di stato (quante $x$ ci sono).\newline
    \textbf{Lineare}: se $f$ e $g$ sono lineari in $x$ e in $u$ (non importa che lo siano in $t$), da notare che una funzione del tipo $x(t) \cdot u(t)$ non è lineare.\newline
    \textbf{Tempo invariante}: se in $f$ e $g$ non compare esplicitamente $t$;\newline
    \textbf{Strettamente proprio}: se in $g$ non compare $u$.\newline
    \textbf{SISO}: single input, single output; cioè se $u$ e $y$ sono scalari.
    \subsection*{Equilibrio}
    \subsubsection*{Caso generale}
    Dato l'ingresso costante $u = \bar{u}$ e detto $\bar{x}$ l'equilibrio cercato, in generale si ha:\newline
    \textbf{TC}: Soluzioni di $f(\bar{x},\bar{u}) = 0$.\newline
    \textbf{TD}: Soluzioni di $f(\bar{x}, \bar{u}) = \bar{x}$.\newline
    Per trovare le uscite di equilibrio $\bar{y}$ è sufficiente applicare gli stati di equilibrio $\bar{x}$ trovati all'uscita e vedere se l'espressione non perde senso e se produce soluzioni reali.
    \subsubsection*{Caso lineare}
    Se il sistema è lineare:\newline
    \textbf{TC, LTI}: Soluzioni di $A\bar{x} + b \bar{u} = 0$.\newline
    \textbf{TD, LTI}: Soluzioni di $A\bar{x} + b \bar{u} = \bar{x}$.\newline
    Se esiste $\bar{x}$, allora per forza esiste un uscite di equilibrio $\bar{y}$
    \subsubsection*{Caso non lineare}
    Se il sistema \textbf{non} è lineare:\newline
    L'uscita $\bar{y}$ potrebbe non avere senso per gli equilibri $\bar{x}$ trovati. 
    \subsection*{Movimento}
    \subsubsection*{Formula di Lagrange TC, LTI}
    \textbf{Per lo stato}:
    \[
            \begin{split}
            x(t) &= x_L(t) + x_F(t) =\\
            &=e^{At} x(0) + \int_{0}^{t}e^{A(t-\tau)}bu(\tau)d \tau
            \end{split}
    \]
    \[
        \begin{cases}
            x_L(t) = e^{At} x(0)\\
            x_F(t) = \int_{0}^{t}e^{A(t-\tau)}bu(\tau)d \tau
        \end{cases}
    \]
    \textbf{Per l'uscita}:
    \[
            \begin{split}
            y(t) 1 &= y_L(t) + y_F(t) =\\
            &= ce^{At}x(0) + c \int_{0}^{t}e^{A(t-\tau)}bu(\tau)d \tau + du(t)
            \end{split}
    \]
    \[
        \begin{cases}
            y_L(t) = ce^{At}x(0)\\
            y_F(t) = c \int_{0}^{t}e^{A(t-\tau)}bu(\tau)d \tau + du(t)
        \end{cases}
    \]
    \subsubsection*{Formula di Lagrange TD, LTI}
    \textbf{Per lo stato}:
    \[
            \begin{split}
            x(k) &= x_L(k) + x_F(k) =\\
            &=A^k x(0) + \sum_{l=0}^{k-1}A^{k-l-1}bu(l)
            \end{split}
    \]
    \[
        \begin{cases}
            x_L(k) A^k x(0)\\
            x_F(k) \sum_{l=0}^{k-1}A^{k-l-1}bu(l)
        \end{cases}
    \]
    \textbf{Per l'uscita}:
    \[
        \begin{split}
            y(k) &= y_L(k) + y_F(k) =\\
            &= cx(k)+du(k) = \\
            &=cA^k x(0) + c\sum_{l=0}^{k-1}A^{k-l-1}bu(l) + du(k)
        \end{split}
    \]
    \[
        \begin{cases}
            y_L(k) = cA^k x(0)\\
            y_F(k) = c\sum_{l=0}^{k-1}A^{k-l-1}bu(l) + du(k)
        \end{cases}
    \]
    \subsubsection*{Esponenziale di matrice (con $A$ diagonalizzabile)}
    $A$ è \textbf{diagonalizzabile} se:
    \begin{itemize}
        \item il numero di autovalori contati con la loro molteplicità è pari all’ordine della matrice;
        \item la molteplicità geometrica di ciascun autovalore coincide con la relativa molteplicità algebrica;
        \item una matrice quadrata di ordine $n$ che ammette esattamente $n$ autovalori distinti è sicuramente diagonalizzabile.
    \end{itemize}
    Per calcolare $e^{At}$ si seguono i seguenti passaggi:
    \begin{itemize}
        \item Calcolare gli autovalori di $A$ (risolvere $det[A-\lambda I] = 0$, oppure se matrice triangolare, gli autovalori sono sulla diagonale);
        \item Calcolare gli autovettori corrsipondenti per ogni autovalore \newline (risolvere $[A-\lambda_i I] \cdot \left[\begin{matrix}
            x\\y
        \end{matrix}\right] = \left[\begin{matrix}
            0\\0
        \end{matrix}\right]$);
        \item definire la matrice diagonalizzante $T$ come l'accostamento degli autovettori trovati (ricordando l'ordine) e calcolare $T^{-1}$. Per l’inversa della generica matrice $T$ 2x2 si moltiplica $\frac{1}{det(T)}$ per la matrice ottenuta da $T$ scambiando di posto i termini sulla diagonale principale e invertendo
        il segno dei termini sulla diagonale secondaria.
        \item notare che $T^{-1} A T = D = $ matrice con gli autovalori di $A$ lungo la diagonale nell'ordine in cui compaiono gli autovettori in $T$.
        \item Calcolare $e^{At}$:\newline
        $e^{At} = e^{TDT^{-1} t} = T e^{Dt} T^{-1} = \dots$
    \end{itemize}
    \subsubsection*{Movimento libero con Jordanizzazione (con $A$ non diagonalizzabile)}
    Se la matrice $A$ non è diagonalizzabile calcolare $e^{At}$ col metodo spiegato prima non è fattibile, piuttosto usare questo procedimento:
    \begin{itemize}
        \item Calcolare gli autovalori di $A$;
        \item Se ci sono autovalori coincidenti, cercare di calcolare gli autovettori corrispondenti (risulterà possibile se e solo se la molteplicità geometrica è pari alla molteplicità algebrica). Se non si riescono a trovare abbastanza autovettori bisogna usare la Jordanizzazione, vediamo come fare.
        \item per ogni autovalore multiplo, chiamiamolo per semplicità $\lambda$, bisogna cercare gli autovettori generalizzati corrispondenti e da questi creare una catena di autovettori.
        \item Il primo autovettore generalizzato è quello classico calcolato come soluzione di $(A-\lambda I_n) x = 0$.
        \item Il secondo autovettore generalizzato è calcolato come soluzione di $(A-\lambda I_n)^2 x = 0$, dove per $(A-\lambda I_n)^2$ è sufficiente fare il prodotto della matrice per sè stessa. E' tipico che un autovettore generalizzato abbia come soluzione un insieme di soluzioni, se siamo al secondo, tipicamente ce ne saranno due.
        \item Tutti gli altri autovettori generalizzati si calcolano allo stesso modo incrementando di uno l'esponente ogni volta.
        \item Una volta trovati tutti gli autovettori generalizzati bisogna fare una catena di autovettori.
        \item A partire dall'ultimo autovettore generalizzato trovato si sceglie un vettore, che chiamo qua $v_n$, fra quelli della soluzione che non appartenga all'insieme dei vettori soluzione dell'autovettore generalizzato precedente. Una volta selezionato, si trova l'autovettore precedente come $v_{n-1} = (A- \lambda I_n)v_n$. E si prosegue così anche per quello prima: $v_{n-2} = (A-\lambda I_n) v_{n-1}$.
        \item una volta terminata la catena di autovettori, questi, accostati in colonna, rappresentano la matrrice jordanizzante $P$, tale che $P^{-1} A P = J =$ matrice in forma canonica di Jordan.
    \end{itemize}
    Vediamo ora come trovare la forma canonica di Jordan della matrice $A$ nel caso 2x2:
    \begin{itemize}
        \item se $\lambda_1 \neq \lambda_2$, allora la matrice di Jordan è la matrice diagonale classica;
        \item se $\lambda_1 = \lambda_2$:
        \begin{itemize}
            \item se ammette due autovettori, allora siamo ancora nella matrice diagonale classica;
            \item se la matrice ammette un solo autovettore, allora abbiamo una matrice di Jordan: $\left[\begin{matrix}
                \lambda & 1\\ 0 & \lambda
            \end{matrix}\right]$
        \end{itemize}
    \end{itemize}
    Vediamo ora come trovare la forma canonica di Jordan della matrice $A$ nel caso 3x3:
    \begin{itemize}
        \item se $\lambda_1 \neq \lambda_2 \neq \lambda_3$ allora la matrice di jordan è la solita diagonale;
        \item se $\lambda_1 = \lambda_2 = \lambda$ e $\lambda_3 \neq \lambda$ allora:
        \begin{itemize}
            \item se $\lambda$ ammette due autovettori, allora siamo alla diagonale solita;
            \item se $\lambda$ non ammette due autovettori, allora la matrice di Jordan:$\left[\begin{matrix}
                \lambda & 1 & 0 \\
                0 & \lambda & 0\\
                0 & 0 & \lambda_3
            \end{matrix}\right]$
        \end{itemize}
        \item se $\lambda_1 = \lambda_2 = \lambda_3 = \lambda$, allora:
        \begin{itemize}
            \item se $\lambda$ ammette tre autovettori, allora siamo alla solita diagonale;
            \item se $\lambda$ ammette due autovettori, allora la matrice di jordan: $\left[\begin{matrix}
                \lambda & 1 & 0 \\
                0 & \lambda & 0\\
                0 & 0 & \lambda
            \end{matrix}\right]$
            \item se $\lambda$ ammette un solo autovettore, allora la matrice di Jordan: $\left[\begin{matrix}
                \lambda & 1 & 0 \\
                0 & \lambda & 1\\
                0 & 0 & \lambda
            \end{matrix}\right]$
        \end{itemize}
    \end{itemize}
    Una volta determinate le matrici jordanizzanti e la matrice di jordan si può proseguire a calcolare il movimento libero:
    \begin{itemize}
        \item partendo dal sistema $\dot{x} = A x$, il movimento libero è $x_L(t) = e^{At}x(0)$;
        \item per prima cosa si fa un cambio di variabile: $\bar{x} = P^{-1}x$, per cui il sistema diventa $P \bar{\dot{x}} = A P \bar{x}$, e spostando $P$ otteniamo $\bar{\dot{x}} = P^{-1} A P \bar{x} = J \bar{x}$.
        \item Siccome la matrice di Jordan è triangolare alta si può ora evitare di usare le matrici e trasformare il sistema in forma scalare. Per esempio, ipotizzando $J = \left[\begin{matrix}
            a & b \\ 0 & c
        \end{matrix}\right]$ otteniamo il sistema $\begin{cases}
            \bar{\dot{x}}_1 = a \bar{x}_1 + b \bar{x}_2\\
            \bar{\dot{x}}_2 = c \bar{x}_2
        \end{cases}$.
        \item la seconda equazione contiene solo $\bar{x}_2$ e quindi il suo movimento libero è $\bar{x}_2 = e^{ct}\bar{x}_2(0)$
        \item Il movimento libero della prima equazione è ora calcolabile come moviemento completo (!) considerando $b \bar{x}_2$ come fosse un ingresso: $\bar{x}_1 = e^{at}\bar{x}_1(0) + \int_{0}^{t} e^{a(t-\tau)} b \bar{x}_2(\tau) d \tau$ e sostituendo il $\bar{x}_2(\tau)$ trovato al punto precedente.
        \item Abbiamo ora trovato le due componenti del vettore movimento libero per $\bar{x}_L$, bisogna però sostituire i valori iniziali $\bar{x}(0) = P^{-1}x(0)$, e, infine, non ci resta che tornare alla variabile iniziale: $x_L (t) = P \bar{x}_L$
    \end{itemize}
    \subsubsection*{Osservazioni}
    \begin{itemize}
        \item Se è richiesto il calcolo del movimento dell'uscita, è sufficiente calcolare il movimento dello stato e sostituirlo nell'equazione dell'uscita del sistema.
        \item Se gli autovalori di $A$ sono numeri complessi: una volta ricondotti i numeri complessi in $x_L$ alla loro forma trigonometrica ($cos(\theta) + i sin(\theta) = e^{i \theta}$), si prende la sola parte reale, l'unità immaginaria deve scomparire.
        \item Alla fine in $x_L$ devono comparire somme di termini del tipo $e^{\alpha t} cos(\omega t)$ e/o $e^{\alpha t} sin(\omega t)$, dove $\alpha$ e $\omega$ sono rispettivamente perti reali e immaginarie di autovalori di $A$. In realtà si possono trovare anche altri termini, ma in via generale se si trova un coefficiente del tempo all'esponente che non è parte reale di nessun autovalore di $A$, il risultato è certamente errato.
        \item TODO: esercizio 2.3, caso autovalore multipli, questioni sui autovettori generalizzati\dots.
        \item Il movimento libero dipende linearmente solo dallo stato iniziale e non dall’ingresso, il movimento forzato dipende linearmente solo dall’ingresso e non dallo stato iniziale.
    \end{itemize}
    \subsection*{Stabilità}
    \begin{itemize}
        \item Tutti gli equilibri hanno le stesse caratteristiche di stabilità.
        \item Nei sistemi lineari (tempo invarianti) la stabilità è una proprietà del sistema, e non una proprietà dell’equilibrio. 
        \item Nei sistemi \textbf{asintoticamente stabili} i movimenti \textbf{liberi} di stato e di uscita tendono a $0$ per $t \rightarrow \infty$ (dimenticano lo stato inizile, movimento libero trascurabile a lungo andare) qualunque sia lo stato iniziale, mentre se li si sottopone a ingresso costante i movimenti (complessivi, non solo liberi) di stato e di uscita tendono ai medesimi valori costanti qualunque sia lo stato iniziale;
        \item Nei sistemi \textbf{instabili} il movimento \textbf{libero} di stato e di uscita diverge a patto di alcune eccezioni. Diverge in generale anche il movimento (complessivo, non solo libero) di stato e di uscita a frornte di un ingresso costante.
        \item nei sistemi \textbf{semplicemente stabili} i movimenti \textbf{liberi} di stato e di uscita nè divergono nè tendono a zero e il loro comportamento asintotico non è lo stesso per qualunque stato iniziale.
    \end{itemize}
    \subsubsection*{Criteri di stabilità}
    \textbf{tempo continuo}:
    \begin{itemize}
        \item Tutti gli autovalori di $A$ hanno $Re < 0 \Longleftrightarrow $ sistema AS;
        \item Almeno un autovalore di $A$ ha $Re > 0 \Longrightarrow$ sistema I;
        \item Tutti gli autovalori di $A$ hanno $Re \leq 0$ e ne esiste almeno uno con $Re = 0$ $\Longrightarrow$ $\begin{cases}
            \text{sistema I;}\;\\
            \text{oppure sistema S, ma non AS.}\;
        \end{cases}$. \newline
        Per capire se si tratta di un sistema stabile o instabile bisogna andare a calcolare il movimento libero per un generico ingresso $x(0)$ e vederne il comportamento per $t \rightarrow \infty$. Se il movimento libero rimane sempre limitato allora il sistema è stabile, se il movimento libero diverge (anche una sola delle componenti del movimento libero) allora il sistema è instabile. \newline
        Esiste anche un altro metodo: guardando la matrice di Jordan, se il più grande miniblocco di Jordan ha dimensione $1$ allora il sistema è stabile, altrimenti è instabile. Un buon metodo per ricordarlo è usare i seguenti due esempi che abbiamo visto a esercitazione:
        \[
            \left[\begin{matrix}
                0 & 0 \\
                0 & 0
            \end{matrix}\right] \;\;\text{due miniblocchi di dimensione 1, quindi S}\;
        \]
        \[
            \left[\begin{matrix}
                0&1\\
                0&0
            \end{matrix}\right] \;\; \text{un miniblocco di dimensione 2, quindi I}\;
        \]
    \end{itemize}
    \textbf{tempo discreto}:
    \begin{itemize}
        \item Tutti gli autovalori di $A$ hanno $|\lambda_i| < 1$ $\Longleftrightarrow$ sistema AS.
        \item Almeno un autovalore di $A$ con modulo $|\lambda_i| > 1$ $\Longrightarrow$ sistema I.
        \item Tutti gli autovalori di $A$ hanno $|\lambda_i| \leq 1$ e ne esiste almeno uno tale che $|\lambda_1| = 1$ $\Longrightarrow$ $\begin{cases}
            \text{sistema I;}\;\\
            \text{oppure sistema S, ma non AS.}\;
        \end{cases}$. \newline
        Per capire se il sistema è instabile o stabile nell'ultimo punto guarda il caso a tempo continuo.
    \end{itemize}
    \textbf{oss.} Errore tipico: Nel caso a tempo continuo si guarda la parte reale degli autovalori, nel caso a tempo discreto si guarda il modulo (!) degli autovalori.
    \subsubsection*{Criteri di stabilità dedotti dalla matrice $A$}
    \begin{itemize}
        \item Se il sistema è asintoticamente stabile, allora $tr(A)$ è negativa, ma non vale il viceversa.
        \item se $det(A) = 0$ esiste $S_i = 0$ $\Longrightarrow$ no AS.
        \item se $tr(A) >0$ $\Longrightarrow$ sistema I.
        \item se $tr(A) = 0$ $\Longrightarrow$ no AS.
        \item Se $Re(S_i)<0$ per ogni $i$ (cioè se il sistema è asintoticamente stabile), allora i coefficienti di $\Pi(S)$ sono tutti concordi e non nulli \newline
        \textbf{oss.} Errore tipico: il viceversa vale solo per polinomi del secondo ordine.
    \end{itemize}
    \textbf{oss.} Per stabilire se un sistema è asintoticamente stabile abbiamo due possibilità: per prima cosa con i primi due dei tre criteri appena esposti stabiliamo se non è asintoticamente stabile, altrimenti, se non abbiamo avuto fortuna con questi criteri, usiamo il criterio di Routh. Un caso particolare è rappresentato dai polinomi di secondo ordine, in cui possiamo evitare di usare Routh e usare il terzo criterio appena visto.
    \subsubsection*{Routh}
    \[
        \Pi(s) = a_0s^n + a_1 s^{n-1} + \dots + a_{n-1}s + a_n
    \]
    Prime due righe
    \[
        \begin{matrix}
            a_0 & \;\;\;\;\;\; a_2 & \;\;\;\;\;\;\dots\\
            \;\;\downarrow & \nearrow \;\; \downarrow & \nearrow \;\; \downarrow\\
            a_1 & \;\;\;\;\;\; a_3 & \;\;\;\;\;\;\dots 
        \end{matrix}
    \]
    a seconda che il numero di termini sia pari (le due righe sono di pari lunghezza) o dispari (la prima riga ha un termine in più della seconda, per cui si aggiunge uno $0$) l'ultima colonna può terminare in due modi:
    \[
        \begin{matrix}
            \dots & a_{n-1}\\
            \;\\
            \dots & a_n
        \end{matrix}\;\;\;\;\;\;\;\;\;\;\; \text{oppure}\;\;\;\;\;\;\;\;\;\;\; \begin{matrix}
            \dots &a_n\\
            \;\\
            \dots & 0 
        \end{matrix}
    \]
    In totale, considerando anche le prime due righe, ci sono $n+1$ righe.\newline
    Ogni riga dalla terza in poi dipende dalle due precedenti seguendo una regola:
    \[
        \begin{matrix}
            h_1 & h_2 & h_3 &\dots\\
            \;\\
            q_1 & q_2 & q_3 & \dots\\
            \;\\
            w_1 & w_2 & w_3 & \dots
        \end{matrix}
    \]
    prese due generiche righe ($h_i$ e $q_i$), i termini della riga successiva ($w_i$) si costruiscono come $w_i = - \frac{1}{q_1} det\left[\begin{matrix}
        h_1 & h_{i+1} \\
        q_1 & q_{i+1}
    \end{matrix}\right]$.\newline
    Se manca un termine in una delle righe precedenti ($h$ e $q$) si assume nullo.\newline
    Se troviamo un elemento nullo in prima colonna, ci si ferma, sicuramente il sistema non è asintoticamente stabile, e siamo in presenza di un caso particolare che non ci permette di calcolare la tabella di Routh.\newline
    \newline
    Un sistema dinamico con polinomio caratteristico $\Pi(s)$ è asintoticamente stabile se e solo se tutti gli elementi della prima colonna della tabella di Routh sono concordi (e non nulli).
    \subsection*{Linearizzazione}
    \subsubsection*{Linearizzazione di sistemi tempo invarianti non lineari nell'intorno di un equilibrio}
    Dato il sistema dinamico 
    \[
        \begin{cases}
            \dot{x}_1(t) = f_1(x_1(t),x_2(t),\dots,x_n(t),u(t))\\
            \dot{x}_2(t) = f_2(x_1(t),x_2(t),\dots,x_n(t),u(t))\\
            \dots\\
            \dot{x}_n(t) = f_n(x_1(t),x_2(t),\dots,x_n(t),u(t))\\
            y(t) = g(x_1(t),x_2(t),\dots,x_n(t),u(t))
        \end{cases}
    \]
    e un suo equilibrio $(\bar{x}, \bar{u})$ a fronte dell'ingresso costante $\bar{u}$, tale sistema è approssimabile con uno lineare e stazionario ottenuto dall'espansione in serie delle $f_i$ e $g$ al prim'ordine:
    \[
        \begin{cases}
            \dot{\delta x} (t) = A \delta x(t) + b \delta u(t)\\
            \delta y (t) = c \delta x (t) + d \delta u (t)
        \end{cases}
    \]
    con:
    \[
        A = \left[\begin{matrix}
            \frac{\delta f_1 (x,u)}{\delta x_1}_{\bar{x}, \bar{u}} & \frac{\delta f_1 (x,u)}{\delta x_2}_{\bar{x}, \bar{u}} & \dots & \frac{\delta f_2 (x,u)}{\delta x_n}_{\bar{x}, \bar{u}}\\
            \frac{\delta f_2(x,u)}{\delta x_1}_{\bar{x}, \bar{u}} & \frac{\delta f_2(x,u)}{\delta x_2}_{\bar{x}, \bar{u}} & \dots & \frac{\delta f_1(x,u)}{\delta x_n}_{\bar{x}, \bar{u}}\\
            \dots & \dots & \dots & \dots\\
            \frac{\delta f_n(x,u)}{\delta x_1}_{\bar{x}, \bar{u}} & \frac{\delta f_n (x,u)}{\delta x_2}_{\bar{x}, \bar{u}} & \dots & \frac{\delta f_n (x,u)}{\delta x_n}_{\bar{x}, \bar{u}} 
        \end{matrix}\right]
    \]
    \[
        b = \left[\begin{matrix}
            \frac{\delta f_1 (x,u)}{\delta u}_{\bar{x}, \bar{u}}\\
            \frac{\delta f_2 (x,u)}{\delta u}_{\bar{x}, \bar{u}}\\
            \dots\\
            \frac{\delta f_n (x,u)}{\delta u}_{\bar{x}, \bar{u}}
        \end{matrix}\right]
    \]
    \[
        c = \left[\begin{matrix}
            \frac{\delta g(x,u)}{\delta x_1}_{\bar{x}, \bar{u}} &
            \frac{\delta g (x,u)}{\delta x_2}_{\bar{x}, \bar{u}} & 
            \dots &
            \frac{\delta g (x,u)}{\delta x_n}_{\bar{x}, \bar{u}}
        \end{matrix}\right]
    \]
    \[
        d = \frac{\delta g (x,u)}{\delta u}_{\bar{x}, \bar{u}}
    \]
    dove il pedice $|_{\bar{x}, \bar{u}}$ indica che sono derivate parziali valutate nell'equilibrio, e
    \[
        \delta x := x-\bar{x} \;\;\;\;\;\delta u := u- \bar{u} \;\;\;\;\; \delta y = := y- \bar{y}
    \]
    \textbf{oss.} Per i sistemi non lineari la stabilità non è una proprietà del sistema, quindi gli equilibri non condividono per forza la stessa "tipologia" di stabilità (AS/S/I). Di conseguenza è necessario analizzare la stabilità per ciascuno degli equilibri.
    \subsubsection*{Stabilità dell'equilibrio di sistemi tempo invarianti non lineari}
    La stabilità di un equilibrio si può studiare basandosi sul sistema linearizzato nell'intorno di quell'equilibrio:
    \begin{itemize}
        \item se il sistema linearizzato è AS, allora anche l'equilibrio è AS;
        \item se il sistema linearizzato è I, allora anche l'equilibrio è I;
        \item se il sistema linearizzato è S, allora nulla si può dire sulla stabilità dell'equilibrio, che in tal caso dipende da termini dello sviluppo in serie di $f$ di grado superiore a uno.
    \end{itemize}
    \subsection*{Trasformate e funzioni di trasferimento a TC}
    \subsubsection*{Laplace}
    \[
        V(s) := \mathcal{L}[v(t)]
    \]
    \textbf{Calcolo della trasformata di Laplace}: $\mathcal{L}[\_\_] =  \int_{0}^{\infty}\_\_ e^{-st} dt$.\newline
    \textbf{Linearità}: $\mathcal{L}[\alpha_1 v_1(t) + \alpha_2 v_2(t)] = \alpha_1 \mathcal{L}[v_1(t)] + \alpha_2 \mathcal{L}[v_2(t)]$.\newline
    \textbf{Derivata}: $\mathcal{L}\left[ \frac{d v(t)}{dt} \right] = s \mathcal{L}[v(t)] - v(0)$.\newline
    \textbf{Integrale}: $\mathcal{L}\left[ \int_{0}^{t} v(\tau) d \tau \right] = \frac{1}{s} \mathcal{L}[v(t)]$.\newline
    \textbf{Ritardo}: $ \mathcal{L}[ v(t - \tau)] = e^{-s \tau} \mathcal{L}[v(t)]$ (spesso utilizzata al contrario per Heaviside: $\mathcal{L}^{-1}\left[\frac{N(s)}{D(s)}e^{-s \tau}\right] \rightarrow $ Heaviside di $\frac{N(s)}{D(s)}$ ottengo $y(t)$, poi con $e^{-s \tau}$ aggiungo ritardo $\tau$ e $\rightarrow  y(t- \tau)$).\newline
    \renewcommand{\arraystretch}{2}
    \begin{center}
        \begin{tabular}{ |c|c| } 
        \hline
        \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$v(t)$ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;& \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$V(s)$ \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\\ 
        \hline
        $k \cdot imp(t)$ & $k \cdot 1$ \\ 
        $k \cdot sca(t)$ & $k \cdot \frac{1}{s}$  \\ 
        $k \cdot ram(t) =k \cdot t \cdot  sca(t)$ & $k \cdot \frac{1}{s^2}$ \\
        $k \cdot e^{at}sca(t)$ & $k \cdot \frac{1}{s-a}$ \\ 
        $t^{n}\cdot e^{at}sca(t)$ & $\frac{n!}{(s-a)^{n+1}}$\\ 
        $\frac{1}{(n-1)!} t^{n-1}e^{-at}$ & $\frac{1}{(s+a)^n}$\\
        \hline
        \end{tabular}
    \end{center}
    \renewcommand{\arraystretch}{1}
    Notiamo che i segnali trigonometrici sono rappresentabili come esponenziali complessi, per esempio $sin(\omega t) = \frac{e^{j \omega t}- e^{-j \omega t}}{2j} \dots$ e così possiamo ricavare le \textbf{trasformate di Laplace di tutte le funzioni trigonometriche}.\newline
    \newline
    \textbf{Teorema del valore iniziale}:\newline
    Se $V(s) = \mathcal{L}[v(t)]$, allora $v(0) = \lim_{s\rightarrow +\infty} s \cdot V(s)$, oppure $v(0^+) = \lim_{s\rightarrow \infty}s \cdot V(s)$.\newline
    \newline
    \textbf{Teorema del valore finale}:\newline
    Se $V(s) = \mathcal{L}[v(t)]$ ed esiste $\lim_{t\rightarrow +\infty} v(t)$ o equivalentemente $V(s)$ ha solo poli con $Re< 0$ o nell'origine, allora $\lim_{t\rightarrow +\infty} v(t) = \lim_{s\rightarrow 0} s \cdot V(s)$.
    \subsubsection*{Antitrasformazione con Heaviside}
    \[
        V(s) = \frac{N(s)}{D(s)}
    \]
    con $N,D$ polinomi in $s$.\newline
    Le radici di $N(s)$ sono gli \textbf{zeri}, mentre le radici di $D(s)$ sono i \textbf{poli}.\newline
    \begin{itemize}
        \item fattorizzare $D(s)$ in modo che sia espresso come prodotto di termini del tipo $(s-p)$ (\textbf{polo reale semplice}) oppure $(s-p)^n$ (\textbf{polo reale multiplo}):
        \item \textbf{polo reale semplice}: $\frac{N(s)}{\dots(s-p)\dots} = \dots + \frac{\alpha}{s-p} + \dots$.
        \item \textbf{polo reale multiplo}: $\frac{N(s)}{\dots (s-p)^n \dots} = \dots + \frac{\alpha_1}{s-p} + \frac{\alpha_2}{(s-p)^2} + \dots + \frac{\alpha_n}{(s-p)^n} + \dots$
    \end{itemize}
    A seguito della scomposizione l'antitrasformata è facilmente calcolabile come usando le trasformate notevoli.
    \subsubsection*{Formula di Lagrange nel dominio delle trasformate}
    \textbf{Per lo stato}:
    \[
        X(s) = X_L(s) + X_F(s)
    \]
    \[
        \begin{cases}
            X_L(s) = (sI-A)^{-1} x(0)\\
            X_F(s) = (sI-A) ^{-1} b U(s)
        \end{cases}
    \]
    \textbf{Per l'uscita}:
    \[
        Y(s) = cX(s) + dU(s) = Y_L(s) + Y_F(s)
    \]
    \[
        \begin{cases}
            Y_L(s) = c(sI-A)^{-1} x(0)\\
            Y_F(s) = [c(sI-A)^{-1} b + d]U(s)
        \end{cases}
    \]
    Spesso può essere utile calcolare la $Y_F(s)$ a partire dall'equazione $\frac{Y(s)}{U(s)} = G(s)$
    \subsubsection*{FdT}
    Il tipico sistema dinamico diventa:
    \[
        \begin{cases}
            s X(s) = AX(s) + b U(s)\\
            Y(s) = cX(s) + d U(s)
        \end{cases}
    \]
    \textbf{funzione di trasferimento}:
    \[
        G(s) := c(sI-A)^{-1} b + d = \frac{\tilde{N}(s)}{D(s)} + d = \frac{N(s)}{D(s)}
    \]
    Ricordiamo che $Y_F(s) = G(s) U(s)$.\newline
    \newline
    La funzione di trasferimento è un rapporto di polinomi il cui denominatore $D(s)$ è il polinomio caratteristico della matrice $A$, quindi i poli sono gli autovalori di $A$. In alcuni casi può capitare che alcuni termini del numeratore si semplifichino con alcuni temrini del denominatore e quindi non tutti gli autovalori di $A$ compaiano come poli.\newline
    Se e solo se $d=0$ (cioè se il sistema è strettamente proprio) abbiamo $G(s) = \frac{\bar{N}(s)}{D(s)}$ in cui il grado del numeatore è minore del grado del denominatore.\newline
    Altrimenti (se e solo se $d\neq 0$) abbiamo $G(s) = \frac{\bar{N}(s) + dD(s)}{D(s)} = \frac{N(s)}{D(s)}$, con $N(s) = \bar{N}(s) +dD(s)$, in cui il grado del numeratore è uguale al grado del denominatore.\newline
    \newline
    Calcolo della funzione di trasferimento con un ritardo: il calcolo è del tutto analogo al caso senza ritardo, basta ricordarsi di moltiplicare l'intera funzione di trasferimento per il termine trascendentale che ne rappresenta il ritardo, $G(s) = (c(sI-A)^{-1} b + d) e^{-a \tau}$.
    \subsection*{Raggiungibilità e osservabilità}
    \subsubsection*{Raggiungibilità}
    \textbf{Sistema raggiungibile se e solo se ($\Leftrightarrow$) $M_R$ è non singolare} (determinante diverso da zero), dove:
    \[
        M_R= \;\text{matrice di raggiungibilità}\; =\left[\begin{matrix}
            b & Ab & A^2 b & \dots & A^{n-1}b
        \end{matrix}\right]
    \] 
    dove nel caso SISO ogni suo termine è una matrice colonna $n$x$1$, e quindi in totale è una matrice $n$x$n$.
    \subsubsection*{Osservabilità}
    \textbf{Sistema osservabile se e solo se ($\Leftrightarrow$) $M_O$ è non singolare} (determinante diverso da zero), dove:
    \[
        M_O = \left[\begin{matrix}
            c' & A'c' & \dots & (A^{n-1})' c'
        \end{matrix}\right]
    \]
    \subsubsection*{Cancellazioni}
    Le parti non raggiungibili e/o non osservabili non sono presenti nella funzione di trasferimento.\newline
    Per cancellazione intendiamo il fatto che nel calcolo della funzione di trasferimento alcuni poli
    e zeri si possono cancellare fra di loro, e questi rappresentano proprio le parti non raggiungibili
    e/o non osservabili.\newline
    \newline
    Una calcellazione è \textbf{critica} se avviene al di fuori della regione di asintotica stabilità (a tempo continuo significa che se l'autovalore è cancellato, non ha la parte reale negativa).\newline
    Poichè i poli di $G(s)$ sono gli autovalori della parte raggiungibile e osservabile del sistema, perchè si possa studiare la stabilità (asintotica) del sistema usando $G(s)$, non vi devono essere cancellazioni critiche.
    \newline
    \newline
    Per capire se un FdT ha parti nascoste basta controllare se una radice del numeratore azzera anche il denominatore o se una radice del denominatore annulla il numeratore. 
    \subsection*{Realizzazione}
    Metodo per la \textbf{forma canonica di raggiungibilità} (realizzazione sempre raggiungibile).
    se il grado del numeratore è uguale al grado del denominatore si fa la divisione e si ottiene $G(s) = d + \frac{N(s)}{D(s)}$, da cui si ricava il valore $d$. A questo punto riscriviamo la frazione $\frac{N(s)}{D(s)} = \frac{ b_1 s^{n-1} + b_2 s^{n-2} + \dots + b_n }{ s^n + a_1 s^{n-1} + \dots + a_n }$ e scriviamo le $A, b$ e $c$:
    \[
        A=\left[\begin{matrix}
            0 & 1 & 0 & \dots & 0 \\
            0 & 0 & 1 & \dots & 0 \\
            \dots & \dots &\dots&\dots&\dots\\
            0 & 0 & 0 & \dots & 1\\
            -a_n & -a_{n-1} & \dots & \dots & -a_1
        \end{matrix}\right]
    \]
    \[
        b=\left[\begin{matrix}
            0\\\dots\\0\\1
        \end{matrix}\right]
    \]
    \[
        c=\left[\begin{matrix}
            b_n & b_{n-1} & \dots & b_1
        \end{matrix}\right]
    \]
    \textbf{oss.} la presenza di una cancellazione ci impone il fatto che la realizzazione
    $ (A, b, c, d)$ non può essere raggiungibile e osservabile contemporaneamente. Quindi siccome facciamo una realizzazione raggiungibile, sarà sicuramente non osservabile.
    \subsection*{Schemi a blocchi}
    \textbf{Blocchi in serie}: $u \rightarrow [G_1] \rightarrow  [G_2] \rightarrow y$, con $G_1 = \frac{N_1}{D_1}$ e $G_2 = \frac{N_2}{G_2}$: $\frac{Y}{U} = G_2G_1 = \frac{N_1N_2}{D_2D_1}$.\newline 
    Gli autovalori del sistema complessivo sono i $\{$ poli di $G_1\} U \{$ poli di $G_2\}$.\newline
    $G_1$ e $G_2$ (entrambi) asintoticamente stabili è condizione neccessaria e sufficiente ($\Leftrightarrow$) per avere un sistema complessivo asintoticamente stabile.\newline
    \newline
    \textbf{Blocchi in parallelo}: con $G_1 = \frac{N_1}{D_1}$ e $G_2 = \frac{N_2}{G_2}$: $\frac{Y}{U} = G_1 + G_2 = \frac{N_2D_1 + N_1 D_2}{D_1D_2}$.\newline
    Quindi gli autovalori del sistema complessivo sono $\{\text{poli di $G_1$}\} U \{\text{poli di $G_2$}\}$.\newline
    $G_1$ e $G_2$ (entrambi) asintoticamente stabili è condizione necessaria e sufficiente ($\Leftrightarrow$) per avere un sistema complessivo asintoticamente stabile.\newline
    \newline
    \textbf{Blocchi in retroazione}: con $G_a$ blocco di andata e $G_r$ blocco di retroazione: $\frac{Y}{U} = \frac{G_a}{1 + G_aG_r} = \frac{\text{"andata"}}{1+ \text{"anello"}} = \frac{N_aD_r}{D_aD_r +N_aN_r}$. \newline
    $G_a$ e $G_r$ asintoticamente stabili nè occorrono nè bastano per avere un sistema complessivo asintoticamente stabile.
    \subsubsection*{Costruzione dello schema a blocchi}
    \textbf{Primo metodo (analitico)}
    \begin{itemize}
        \item Si trasforma il sistema $\begin{cases}
            \dot{x} = A x + bu\\ y = cx +d
        \end{cases}$ secondo Laplace: $\begin{cases}
            s X = A X + b U\\ Y = c X + d
        \end{cases}$;
        \item Si esprime il sistema secondo le variabili di stato e secondo l'uscita:$\begin{cases}
            X = \;\text{qualcosa}\;\\ Y = \;\text{qualcosa}\;
        \end{cases}$;
        \item Ora è facile ricostruire lo schema a blocchi.
    \end{itemize}
    \textbf{Secondo metodo (Funzione di trasferimento)}
    \begin{itemize}
        \item Si calcola la funzione di trasferimento $G(s)$;
        \item Ricordando che $Y = G(s) U$ possiamo scrivere il sistema a blocchi come: $Y \longrightarrow \left[G(s)\right] \longrightarrow U$
    \end{itemize}
    \textbf{Terzo metodo (Integratori)}\newline
    Ricordiamo che la funzione integrale nel dominio delle trasformate è rappresentato dall'aggiunta di un termine $\frac{1}{s}$ (\textbf{es.} $y(t) = \int_{0}^{t}u(\tau)d \tau \Rightarrow Y(s) = \frac{1}{s} U(s)$ ).\newline
    Il termine $\frac{1}{s}$ è la funzione di trasferimento dell'integratore.
    \begin{itemize}
        \item Si disegnano $n$ blocchi integratori $\frac{1}{s}$ quante sono le $n$ variabili di stato del sistema;
        \item Per ciascuno di questi blocchi $n$ si mette come ingresso la variabile derivata ($\dot{x}_n$) e come uscita la variabile semplice ($x_n$);
        \item Osservando le matrici $A$ e $b$ si compongono con dei nodi sommatori i vari $\dot{x}_1, \dots, \dot{x}_n$;
        \item Infine osservando le matrici $c$ e $d$ si compone l'uscita.
    \end{itemize}
    [immagine dagli appunti del prof]
    \begin{center}
        \includegraphics[height=2cm]{../lezione8/img1.PNG}
    \end{center}
    Rappresentazioen di dove solitamente si inseriscono i valori delle matrici del sistema all'interno dello schema a blocchi sviluppato con l'integratore.
    \subsection*{Risposta esponenziale}
    Quindi \textbf{in generale} con $u(t) = U e^{\lambda t}$ (con $U$ un numero qualunque che semplicemente amplifica l'esponenziale), se $\lambda$ non è autovalore di $A$, allora esiste uno e uno solo 
    \[
        x(0) = (\lambda I - A)^{-1}b U
    \] tale che 
    \[
        \begin{cases}
            x(t) = (\lambda I -A)^{-1} b U e^{\lambda t}\\
            y(t) = cx(t) + du(t) =  [c(\lambda I -A)^{-1} b + d] U e^{\lambda t} = G(\lambda) u(t)
        \end{cases}
    \]
    Se, inoltre, il sistema è asintoticamente stabile, allora qualunque sia lo stato iniziale $x(0)$, l'uscita tenderà a $y(t) \rightarrow G(\lambda) u(t)$ per $t \rightarrow  \infty$.
    \subsection*{Risposta sinusoidale}
    Dato il sistema dinamico LTI a TC, SISO $\begin{cases}
        \dot{x} = Ax +bu\\ 
        y = cx +du
    \end{cases}$, detta $G(s)$ la sua funzione di trasferimento e considerato l'ingresso $u(t) = U sin(\omega t)$ per $t\geq 0$:
    \begin{itemize}
        \item Se $\mp j \omega$ non sono autovalori di $A$, allora esiste uno e uno solo stato iniziale $x(0)$ tale che $y(t) = |G(j \omega)| U sin(\omega t + arg(G(j \omega)))$ per $t\geq 0$. (Se $\mp j \omega$ sono autovalori di $A$, allora si verifica un fenomeno di risonanza, che però non è argomento di questo corso).
        \item Se INOLTRE il sistema è asintoticamente stabile, allora qualunque sia lo stato iniziale, l'uscita  tenderà a $y(t) \rightarrow |G(j \omega) U sin( \omega t + arg(G(j \omega)))$ per $t \rightarrow  \infty$
    \end{itemize}
    \textbf{definizione}:  Data una funzione di trasferimento $G(s)$, la sua restrizione all'asse immaginario positivo $J^+$, cioè $G(j \omega)$ con $\omega \geq 0$, si dice \textbf{risposta in frequenza} (RF) di $G(s)$.
    \subsection*{Diagramma di Bode}
    $x_{dB} = 20 log_{10}|x|$\newline
    \[
        G(s) = \frac{\mu}{s^g} \cdot \frac{(1 + s \tau_1)(1 + s \tau_2)\dots}{(1 + s t_1)(1 + s t_2)\dots} \cdot \frac{(1 + 2 \frac{\zeta}{\sigma_n}s + \frac{1}{\sigma_n^2}s^2)\dots}{(1 + 2 \frac{\xi}{\omega_n} s + \frac{1}{\omega_n^2}s^2)\dots}
    \]
    \[
        \begin{matrix}
            G_a(s) = \mu & \;\; & G_c(s) = 1+ s t\\
            G_b(s) = \frac{1}{s^g} & \;\; & G_d(s) = 1 + 2 \frac{\xi}{\omega_n}s + \frac{1}{\omega_n^2}s^2
        \end{matrix}
    \]
    \subsubsection*{Metodo di tracciamento}
    Per prima cosa si ricavano i valori di $\mu$, $g$, poi si ricavano tutte le frequenze d'angolo (modulo delle radici di ogni termine al numeratore e al denominatore, escluse quelle in $s=0$) e per ognuna di queste si dice quanti zeri (radici del numeratore) destri (con parte reale positiva) o sinistri (con parte reale negativa) e quanti poli (radici del denominatore) destri (con parte reale positiva) o sinistri (con parte reale negativa) ci sono.\newline
    \newline
    \textbf{Diagramma di Bode del modulo}: 
    \begin{enumerate}
        \item Tracciare il diagramma di Bode del modulo di $\frac{\mu}{s^g}$ (è una retta la cui pendenza viene ricavata da: $-20 \cdot g \frac{dB}{decade}$; per capire dove interseca l'asse delle $\omega$ basta ricavare il valore di $\omega$ per cui $\left| \frac{\mu}{\omega^g} \right| = 1$; se la retta non ha pendenza allora è una retta orizzontale all'altezza di $|\mu|_{dB}$).
        \item Segnare sull'asse delle $\omega$ le frequenze d'angolo dei poli (radici del denominatore) e zeri (radici del numeratore) non in $s=0$ (perchè son già presenti nel punto precedente).\newline
        Quando si incontra una frequenza d'angolo di uno zero, la pendenza aumenta di $1$, quando si incontra una frequenza d'angolo di un polo, la pendenza diminuisce di $1$. (Ricordiamo che per 1 di pendenza si intendono $20 dB/decade$).
    \end{enumerate}
    \textbf{Diagramma di Bode della fase}:
    \begin{enumerate}
        \item Il diagramma di Bode della fase parte al valore di $arg(\frac{\mu}{(j \omega)^g})$, che è calcolabile sommando i contributi di $\mu$ e $\frac{1}{s^g}$ nel seguente modo:
        \[
            \mu \rightarrow \begin{cases}
                0^o \;\;\;& se > 0\\
                -180^o \;\;\; & se <0
            \end{cases} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \frac{1}{s^g}\rightarrow -g \cdot 90^o
        \]
        \item zero "a sinistra" la fase aumenta di $90^o$;\newline
        zero "a destra" la fase diminuisce di $90^o$;\newline
        polo "a sinistra" la fase diminuisce di $90^o$;\newline
        polo "a destra" la fase aumenta di $90^o$.
    \end{enumerate}
    \textbf{Regolo delle fasi}:\newline
    Il tipico diagramma di Bode della fase che facciamo è una approssimazione asintotica che può variare molto rispetto al vero e proprio grafico. Il regolo delle fasi è utilizzato per calcolare la fase esatta (senza approssimazione asintotica) per una specifica frequenza $\bar{\omega}$ calcolando il contributo che ciascun polo e ciascun zero apporta a quella data frequenza $\bar{\omega}$.\newline
    I passaggi da seguire sono i seguenti:
    \begin{itemize}
        \item Si disegna il diagramma di Bode della fase approssimato;
        \item Si pone il regolo delle fasi con la freccia dei 45 gradi sulla $\bar{\omega}$ di cui si desidera calcolare la fase;
        \item Lungo il regolo si leggono i contributi (in modulo) di ogni polo e zero in corrispondenza delle loro frequenze d'angolo;
        \item Per calcolare la fase nel punto $\bar{\omega}$ è ora sufficiente combinare i valori trovati al punto precedente (ricordando di aggiungere il segno corretto e  di moltiplicarli per il numero di poli o zeri presenti), inoltre bisogna ricordarsi anche il valore di partenza della fase che ovviamente nel regolo non è espresso.
    \end{itemize}
    \subsection*{Diagramma polare}
    A differenza dei diagrammi di Bode, i diagrammi polari non hanno metodi comodi per tracciarne l'andamento. Possiamo però comprenderne l'andamento tramite un'analisi del comportamento asintotico per $\omega \rightarrow 0^+$ e per $\omega \rightarrow  \infty$ e tramite un'analisi dell'aspetto qualitativo.\newline
    \newline
    Quindi studiamo la generica funzione di trasferimento $G(s)$ nella classica forma con cui la analizzeremmo per Bode.
    \begin{itemize}
        \item per $\omega \rightarrow  0$:
        \begin{itemize}
            \item se $g=0$: $G(0) = \mu$;
            \item se $g<0$: $G(0) = 0$;
            \item se $g>0$: il diagramma polare "parte all'infinito", dalla direzione $-90^o \cdot  g$;
        \end{itemize}
        \item per $\omega \rightarrow  \infty$:
        \begin{itemize}
            \item se il numero di poli di $G(s)$ è $>$ del numero di zeri di $G(s)$ $\rightarrow $ il diagramma polare finisce nell'origine;
            \item se il numero di poli di $G(s)$ è uguale al numero di zeri di $G(s)$ $\rightarrow $ il diagramma polare finisce su un asse.
        \end{itemize}
        \item in generale l'andamento del diagramma polare si può dedurre dai diagrammi di bode del modulo e della fase, ricordando che il modulo è la distanza dall'origine e la fase è l'angolo.
    \end{itemize}
    \subsection*{Ritardi}
    Analiziamo gli effetti di un ritardo applicato a una funzione di trasferimento. Prendiamo $G(s) = \frac{N(s)}{D(s)} e^{-s \tau} = G_R(s) e^{-s \tau}$, in cui $G_R(s)$ rappresenta la dianmica razionale (cioè una tipica funzione di trasferimento) e $e^{-s \tau}$ un ritardo.
        \[
            G(j \omega) = G_r(j \omega) e^{- j \omega \tau} = \begin{cases}
                |G(j \omega)| = |G_R(j \omega)|\\
                arg(G(j \omega)) = arg(G_R(j \omega)) - \omega \tau
            \end{cases}
        \]
        Notiamo che il ritardo non ha effetti sul modulo, ma solo sulla fase con il termine $- \omega \tau$ che è espresso in radianti (\textbf{oss.} Errore tipico è scordarsi di trasformare le radianti in gradi).\newline
        Quindi gli effetti del ritardo sul diagramma di Bode del modulo sono nulli, mentre sul diagramma di Bode della fase il ritardo ha un contributo lineare $- \omega \tau$, che in scala logaritmica è rappresentato da un esponenziale.\newline
        \newline
        Ai fini pratici (in esame) l'unica cosa che ci può essere richiesta è il calcolo della fase di una funzione di trasferimento ritardata tramite il regolo delle fasi. Per farlo studiamo la funzione di trasferimento ignorando il ritardo e calcoliamo $arg(G(j \omega))$ normalmente con il regolo delle fase, infine ci basta sottrarre $\omega \tau$ (RADIANTI! ricordati di trasformarli in gradi, cioè moltiplicare per $\frac{180^o}{\pi}$). \newline
        \newline
        L'effetto grafico che si ha su un diagramma polare a causa di un ritardo è che l'intero diagramma polare viene "arrotolato su sè stesso".\newline
        [immagine dagli appunti del prof]
        \begin{center}
            \includegraphics[height=3cm]{../lezione17/img2.PNG}
        \end{center}
        Data $G = \frac{N}{D} e^{- j \omega \tau}$ ci sono due casi possibili:
        \begin{itemize}
            \item Caso in cui il grado di $D$ sia maggiore del grado di $N$: il diagramma polare di $G$ dinisce nell'origine con fase tendente a $- \infty$, quindi il diagramma si arrotola su sè stesso come una spirale;
            \item Caso in cui il grado di $D$ sia uguale al grado di $N$: il modulo è costante e la fase tende a $- \infty$, quindi il diagramma diventa una circonferenza percorsa infinite volte.
        \end{itemize}
    \subsection*{Sintesi diretta}
    esercitazione 5, esercizio 2.
    \subsection*{Funzioni fondamentali di un anello di controllo}
    \begin{itemize}
        \item funzione di traferimento d'anello (aperto) $L(s) := R(s) \cdot P(s)$;
        \item funzione di sensitività complementare $T(s) := \frac{L(s)}{1+ L(s)}$;
        \item funzione di sensitività $S(s) := \frac{1}{1+ L(s)}$;
        \item funzione di sensitività del controllo $Q(s) := \frac{R(s)}{1+L(s)}$
        \item $\frac{Y}{W} = \frac{L}{1+L} = T$;
        \item $\frac{Y}{D_r} = - \frac{L}{1+L} = -T$;
        \item $\frac{Y}{D_a} = \frac{1}{1+L} = S$;
        \item $Y = T \cdot W + S \cdot  D_a -T \cdot D_r = T \cdot W + S \cdot D_a - T \cdot D_r$.
    \end{itemize}
    \subsection*{Stabilità di sistemi retroazionati}
    \subsubsection*{Diagramma di Nyquist}
    \textbf{Percorso di Nyquist}: Curva chiusa costituita dall'intero asse immaginario e da una semicirconferenza di raggio infinito giacente nel semipiano destro. Se $G(s)$ ha poli a parte reale nulla, il percorso di Nyquist viene modificato evitando tali poli con semicirconferenze di raggio infinitesimo giacenti nel semipiano destro. Il percorso di Nyquist è percorso in senso antiorario.\newline
    \newline
    \textbf{Diagramma di Nyquist}: Costituito dal diagramma polare e della sua immagine speculare rispetto all'asse reale.
    \subsubsection*{Stabilità asintotica}
    Il numero di giri antiorari del diagramma di Nyquist di $G(s)$ attorno all'oigine è \textbf{uguale} al numero di poli di $G(s)$ circondati dal suo percorso di Nyquist in senso orario \textbf{meno} il numero di zeri di $G(s)$ circondati dal suo percorso di Nyquist in senso orario.\newline
    \newline
    Detto $L(s) = R(s) \cdot P(s)$, allora:\newline
    il numero di giri del diagramma di Nyquist di $L(s)$ attorno al punto $-1$ è \textbf{uguale} al numero di poli di $L(s)$ con $Re> 0$ \textbf{meno} il numero di poli dell'anello chiuso con $Re > 0$.\newline
    \newline
    Poichè per avere la \textbf{stabilità asintotica} dell'anello chiuso si vuole che il numero di poli dell'anello chiuso con $Re > 0$ sia uguale a zero, si ha che deve essere:\newline
    numero di iri del diagramma di Nyquist di $L(s)$ attorno al punto $-1$ è \textbf{uguale} al numero di poli di $L(s)$ con $Re > 0$.
    \subsubsection*{Criterio di Nyquist}
    Considerando il sistema dinamico:
    \begin{center}
        \includegraphics[height=1cm]{../formulario/img1.JPG}
    \end{center}
    \begin{itemize}
        \item Si tracci il diagramma di Nyquist di $L(s)$;
        \item Sia $P_D$ il numero di poli di $L(s)$ con $Re > 0$;
        \item Sia $N$ il numero di giri antiorari del diagramma di Nyquist di $L(s)$ attorno al punto $-1$ dell'asse reale; se il diagramma di Nyquist passa per il punto $-1$ si dirà che $N$ non è ben definito.
    \end{itemize}
    \textbf{Criterio}: il sistema in anello chiuso è asintoticamente stabile $\Leftrightarrow$ $N$ è ben definito e $N = P_D$.\newline
    \textbf{Caso $N$ non ben definito}:\newline
    se $N$ non è ben definito, allora il diagramma di Nyquist passa per $-1$, il sistema in anello chiuso ha poli con parte reale nulla, quindi è \textbf{non asintoticamnete stabile} (stabile o instabile, ma non si può concludere nulla a proposito).\newline
    \textbf{Caso $N \neq P_D$}:\newline
    Se $N$ è ben definito ma $N\neq P_D$, il sistema in anello chiuso è sicuramento \textbf{instabile}.\newline
    \textbf{Caso particolare $P_D = 0$}:\newline
    In questo caso per essere asintoticamente stabile deve essere $N = 0$. Si possono in questo caso definire dei margini di stabilità:
    \begin{itemize}
        \item Margine di modulo: $M_m = min_{\omega} | 1 + L(j \omega)|$;
        \item Margine di guadagno: $K_m = \frac{1}{\alpha}$, dove $\alpha$ è il valore del modulo nel punto in cui interseca l'asse dei reali negativi ($\mathbb{R}^{-}$);
        \item Margine di fase: $\omega_c$: frequenza tache che $|L| = 1$, $\phi_c = arg(L(j \omega_c))$, $\phi_m = -180 - |\phi_c|$.
    \end{itemize}
    \subsection*{Criterio di Bode}
    \begin{itemize}
        \item Sia $P_D = 0$ (cioè $L(s)$ non ha poli con $Re > 0$);
        \item Sia il diagramma di Bode del modulo di $L(s)$ tale che intersechi l'asse $0_{dB}$ una sola volta dall'alto verso il basso (cioè $L$ entra una sola volta nele cerchio unitario e non ne esce più);
        \item Sia $\mu_L$ il guadagno di $L(s)$ e $\phi_m$ il margine di fase;
    \end{itemize}
    Allora il sistema in anello chiuso è asintoticamente stabile se e solo se ($\Leftrightarrow$) $\mu_L > 0$ e $\phi_m > 0^o$
    \subsection*{Sintesi del controllore in retroazione}
    \begin{center}
        \includegraphics[height=3cm]{../formulario/img2.JPG}
    \end{center}
    \subsubsection*{Progetto statico}
    \begin{itemize}
        \item Considero le sole componenti canoniche $w$ e $d_a$ come ingressi di un sistema in anello chiuso e asintoticamente stabile: $w$ e $d_a$ hanno solo poli in $s=0$ e il blocco ha solo poli con $Re<0$ e vale il teorema del valore finale.
        \item Esprimo l'errore a transitorio esaurito con il teorema del valore finale:\newline
        $e_\infty = \lim_{t\rightarrow +\infty} e(t)$ dove $e(t) : = w(t) - y(t)$.
        \item Impongo i vincoli $e_\infty = 0$ oppure $|e_\infty| < $ un certo valore, e determino condizioni du tipo e/o guadagno di $L(s)$, ricordando che in generale:\newline
        $P(s) 0 \frac{\mu_p}{s^{g_p} \cdot  \frac{1+ \dots}{1+ \dots}}$;\newline
        $R(s) = \frac{\mu_r}{s^{g_r}} \cdot  \frac{1+ \dots}{1+ \dots}$;\newline
        $L(s) = R(s) \cdot P(s) \rightarrow \begin{cases}
            \mu_L = \mu_r \cdot \mu_p\\
            g_L = g_r + g_p
        \end{cases}$
    \end{itemize}
    \subsubsection*{Progetto dinamico}
    $T = \frac{L}{1+L} = \begin{cases}
        1 \; \text{se}\; |L| >> 1\\
        L \; \text{se}\; |L| << 1
    \end{cases}$\newline
    $S = \frac{1}{1+L} = \begin{cases}
        \frac{1}{L} \; \text{se}\; |L| >> 1\\
        1 \; \text{se}\; |L| << 1
    \end{cases}$
    \begin{center}
        \includegraphics[height=3cm]{../formulario/img3.JPG}
    \end{center}
    \textbf{Vincolo sulla velocità di risposta}: $\omega_{c_min} < \omega_c < \omega_{c_max}$ (nel diagramma di bode del modulo di $L(s)$, $\omega_c$ è il punto in cui interseca l'asse degli $0_{dB}$). \newline
    \textbf{Vincolo sul grado di stabilità (e assenza di oscillazioni)}: $\phi_m > $ un determinato valore (si verifica con il regolo delle fasi).\newline
    \textbf{Vincolo sulla reiezione di un disturbo in andata}: un disturbo sinusoidale $d_a(t) = A sin (\omega_a \cdot  t)$ con $|A| < \bar{A}$ e $0 \leq \omega_{a_1} \leq \omega_a \leq \omega_{a_2} \leq \omega_c$, devo produrre asintoticamnete (per $t \rightarrow \infty$) su $y$ un effetto di ampiezza non superiore a $\Delta_a$ (ampiezza del massimo effetto che tollero), occorre che $\left| \frac{Y(j \omega)}{D_a(j \omega)} \right| < \frac{\Delta a}{\bar{A}}$ per $\omega_{a_1} \leq \omega \leq \omega_{a_2}$. In definitiva bisogna che:
    \[
        |L(j \omega)| > \frac{\bar{A}}{\Delta a} \;\;\;\text{per}\; \omega_{a_1} \leq \omega \leq \omega_{a_2}
    \]
    \textbf{Vincolo sulla reiezione di un disturbo in retroazione}:
    \end{multicols*}
\end{landscape}